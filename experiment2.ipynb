{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc08c661",
   "metadata": {},
   "source": [
    "\n",
    "# DisentAE Batch Correction Pipeline (Notebook)\n",
    "\n",
    "这个笔记本是将你的 `main.py` 转换成的 `ipynb` 版本。  \n",
    "与命令行参数不同，这里用一个 **Parameters** 单元格来设置参数（等价于 `argparse` 的各项）。\n",
    "\n",
    "> 依赖：`numpy`, `scanpy`, `anndata`, `torch`，以及你本地的 `model.py`、`file.py`（包含 `DisentAE`、`preprocess_batches`、`train_disentae`、`apply_mnn_correction_iterative`、`decode_corrected_expression`、`inputs_signature`、`load_manifest`、`save_manifest` 等）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c2ca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/envs/dachuang310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Using torch 2.8.0+cu128, CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, time\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from anndata import AnnData\n",
    "import torch\n",
    "\n",
    "# 你的项目内模块\n",
    "from model import *\n",
    "from file import *  # 假设包含 inputs_signature / load_manifest / save_manifest 等\n",
    "\n",
    "print(f\"[Info] Using torch {torch.__version__}, CUDA available: {torch.cuda.is_available()}\")\n",
    "sc.settings.verbosity = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eda5900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "细胞/样本名 (行名):\n",
      "Index(['vis1', 'vis2', 'vis3', 'vis4', 'vis5', 'vis6', 'vis7', 'vis8', 'vis9',\n",
      "       'vis10',\n",
      "       ...\n",
      "       'wal4363', 'wal4364', 'wal4365', 'wal4366', 'wal4367', 'wal4370',\n",
      "       'wal4371', 'wal4372', 'wal4374', 'wal4375'],\n",
      "      dtype='object', length=9288)\n",
      "\n",
      "基因名 (列名):\n",
      "Index(['ENSMUSG00000092341', 'ENSMUSG00000029580', 'ENSMUSG00000023043',\n",
      "       'ENSMUSG00000064341', 'ENSMUSG00000031765', 'ENSMUSG00000017009',\n",
      "       'ENSMUSG00000016559', 'ENSMUSG00000064370', 'ENSMUSG00000024661',\n",
      "       'ENSMUSG00000049382',\n",
      "       ...\n",
      "       'ENSMUSG00000036580', 'ENSMUSG00000010663', 'ENSMUSG00000040605',\n",
      "       'ENSMUSG00000039431', 'ENSMUSG00000028634', 'ENSMUSG00000022218',\n",
      "       'ENSMUSG00000020593', 'ENSMUSG00000030905', 'ENSMUSG00000022949',\n",
      "       'ENSMUSG00000028545'],\n",
      "      dtype='object', length=1222)\n",
      "adata.obs 中的所有列（元数据）:\n",
      "Index(['orig.ident', 'nCount_originalexp', 'nFeature_originalexp', 'study',\n",
      "       'cell.class', 'library_size', 'detected_genes', 'BATCH', 'celltype'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read_h5ad('bct_raw.h5ad')\n",
    "\n",
    "# 输出行名 (Observed names)，即细胞名\n",
    "print(\"细胞/样本名 (行名):\")\n",
    "print(adata.obs_names)\n",
    "\n",
    "# 输出列名 (Variable names)，即基因名\n",
    "print(\"\\n基因名 (列名):\")\n",
    "print(adata.var_names)\n",
    "\n",
    "print(\"adata.obs 中的所有列（元数据）:\")\n",
    "print(adata.obs.columns)\n",
    "\n",
    "# # 查看 batch 列的前几行\n",
    "# print(\"batch 列的前5个值:\")\n",
    "# print(adata.obs['batch'].head())\n",
    "\n",
    "# # 统计每个批次有多少个细胞\n",
    "# print(\"每个批次的细胞数量:\")\n",
    "# print(adata.obs['batch'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07777f",
   "metadata": {},
   "source": [
    "## Parameters（请在此处修改）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad6c27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Params]\n",
      "  batch_key: None\n",
      "  outdir: outputs\n",
      "  device: cpu\n",
      "  zc_dim: 32\n",
      "  zb_dim: 16\n",
      "  epochs: 50\n",
      "  batch_size: 256\n",
      "  lr: 0.001\n",
      "  grl_lambda: 1.0\n",
      "  inject_noise_std: 0.1\n",
      "  n_top_genes: 2000\n",
      "  k_mnn: 20\n",
      "  resume: True\n",
      "  force: False\n",
      "  inputs: 1 files -> ['bct_raw.h5ad']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 等价于命令行：\n",
    "# python main.py --inputs neurips2021_s1d3.h5ad neurips2021_s2d1.h5ad neurips2021_s3d7.h5ad --outdir out\n",
    "# 若只传一个 .h5ad，可配合 --batch_key 使用（例如 'batch'）\n",
    "\n",
    "ARGS = {\n",
    "    \"inputs\": [\n",
    "        # 在这里填入你的 .h5ad 路径，支持多个；或只填一个并设置 batch_key\n",
    "        # \"neurips2021_s1d3.h5ad\",\n",
    "        # \"neurips2021_s2d1.h5ad\",\n",
    "        # \"neurips2021_s3d7.h5ad\",\n",
    "        \"bct_raw.h5ad\",\n",
    "    ],\n",
    "    \"batch_key\": None,              # 例如: \"batch\" 或 \"replicate\"\n",
    "    \"outdir\": \"outputs\",\n",
    "\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"zc_dim\": 32,\n",
    "    \"zb_dim\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 1e-3,\n",
    "    \"grl_lambda\": 1.0,\n",
    "    \"inject_noise_std\": 0.1,\n",
    "\n",
    "    \"n_top_genes\": 2000,\n",
    "    \"k_mnn\": 20,\n",
    "\n",
    "    # 训练阶段：默认启用缓存（仅训练阶段）；若 force=True 则无视缓存强制重训\n",
    "    \"resume\": True,\n",
    "    \"force\": False,\n",
    "}\n",
    "\n",
    "os.makedirs(ARGS[\"outdir\"], exist_ok=True)\n",
    "print(\"[Params]\")\n",
    "for k, v in ARGS.items():\n",
    "    if k != \"inputs\":\n",
    "        print(f\"  {k}: {v}\")\n",
    "print(f\"  inputs: {len(ARGS['inputs'])} files -> {ARGS['inputs']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1677041",
   "metadata": {},
   "source": [
    "## 构建运行签名（用于训练缓存判定）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6c4732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': '2025-08-31 22:45:42',\n",
       " 'inputs': [{'path': '/home/luke/project/dachuang/bct_raw.h5ad',\n",
       "   'size': 18279891,\n",
       "   'mtime': 1660820490,\n",
       "   'sha1': '583ece94c4f1ad8b8ac282604b88d0f654dbcb1d'}],\n",
       " 'params': {'zc_dim': 32,\n",
       "  'zb_dim': 16,\n",
       "  'epochs': 50,\n",
       "  'batch_size': 256,\n",
       "  'lr': 0.001,\n",
       "  'grl_lambda': 1.0,\n",
       "  'inject_noise_std': 0.1,\n",
       "  'n_top_genes': 2000,\n",
       "  'k_mnn': 20,\n",
       "  'batch_key': None}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "curr_manifest = {\n",
    "    \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"inputs\": inputs_signature(ARGS[\"inputs\"]),\n",
    "    \"params\": {\n",
    "        \"zc_dim\": ARGS[\"zc_dim\"],\n",
    "        \"zb_dim\": ARGS[\"zb_dim\"],\n",
    "        \"epochs\": ARGS[\"epochs\"],\n",
    "        \"batch_size\": ARGS[\"batch_size\"],\n",
    "        \"lr\": ARGS[\"lr\"],\n",
    "        \"grl_lambda\": ARGS[\"grl_lambda\"],\n",
    "        \"inject_noise_std\": ARGS[\"inject_noise_std\"],\n",
    "        \"n_top_genes\": ARGS[\"n_top_genes\"],\n",
    "        \"k_mnn\": ARGS[\"k_mnn\"],\n",
    "        \"batch_key\": ARGS[\"batch_key\"],\n",
    "    }\n",
    "}\n",
    "old_manifest = load_manifest(ARGS[\"outdir\"])\n",
    "curr_manifest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c89d3f",
   "metadata": {},
   "source": [
    "## 读取数据为按批次的 `AnnData` 列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14654ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] 读取多个批次文件，共 1 个\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "adata_list = []\n",
    "if len(ARGS[\"inputs\"]) == 0:\n",
    "    raise ValueError(\"请在 ARGS['inputs'] 中填写至少一个 .h5ad 路径\")\n",
    "\n",
    "if len(ARGS[\"inputs\"]) == 1 and ARGS[\"batch_key\"] is not None:\n",
    "    ad = sc.read_h5ad(ARGS[\"inputs\"][0])\n",
    "    if ARGS[\"batch_key\"] not in ad.obs:\n",
    "        raise ValueError(f\"batch_key '{ARGS['batch_key']}' 不在 adata.obs 中\")\n",
    "    for b in ad.obs[ARGS[\"batch_key\"]].astype(str).unique():\n",
    "        ad_b = ad[ad.obs[ARGS[\"batch_key\"]].astype(str) == b].copy()\n",
    "        adata_list.append(ad_b)\n",
    "    print(f\"[Info] 从单个 h5ad 依据 '{ARGS['batch_key']}' 拆出 {len(adata_list)} 个批次\")\n",
    "else:\n",
    "    for p in ARGS[\"inputs\"]:\n",
    "        ad = sc.read_h5ad(p)\n",
    "        adata_list.append(ad)\n",
    "    print(f\"[Info] 读取多个批次文件，共 {len(adata_list)} 个\")\n",
    "\n",
    "len(adata_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a394d45",
   "metadata": {},
   "source": [
    "## 预处理（每次执行，不跳过）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6e92db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered out 715 cells that have less than 200 genes expressed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing counts per cell\n",
      "    finished (0:00:01)\n",
      "extracting highly variable genes\n",
      "`n_top_genes` > `adata.n_var`, returning all genes.\n",
      "    finished (0:00:00)\n",
      "[Info] X shape: (8573, 1222), batches shape: (8573,), |HVG∩|=1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/envs/dachuang310/lib/python3.10/functools.py:889: UserWarning: zero-centering a sparse array/matrix densifies it.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' batch_labels_str 的长度与样本数一致，顺序与 batches 相同；之后凡是画 UMAP 或算“批次相关”指标时，都用它替代裸的 batches。 '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X, batches, hvg_list = preprocess_batches(\n",
    "    adata_list, n_top_genes=ARGS[\"n_top_genes\"]\n",
    ")\n",
    "print(f\"[Info] X shape: {X.shape}, batches shape: {batches.shape}, |HVG∩|={len(hvg_list)}\")\n",
    "\n",
    "np.save(os.path.join(ARGS[\"outdir\"], \"X_preprocessed.npy\"), X)\n",
    "np.save(os.path.join(ARGS[\"outdir\"], \"batches.npy\"), batches)\n",
    "with open(os.path.join(ARGS[\"outdir\"], \"HVG_intersection.tsv\"), \"w\") as f:\n",
    "    f.write(\"\\n\".join(hvg_list))\n",
    "\n",
    "# === 将整数批次索引 -> 友好批次名称 ===\n",
    "\"\"\" batch_labels_str 的长度与样本数一致，顺序与 batches 相同；之后凡是画 UMAP 或算“批次相关”指标时，都用它替代裸的 batches。 \"\"\"\n",
    "# if len(ARGS[\"inputs\"]) == 1 and ARGS.get(\"batch_key\"):\n",
    "#     # 单文件 + batch_key：用 obs[batch_key] 的实际取值\n",
    "#     batch_names = []\n",
    "#     for ad in adata_list:\n",
    "#         vals = ad.obs[ARGS[\"batch_key\"]].astype(str).unique().tolist()\n",
    "#         batch_names.append(vals[0] if len(vals) else \"batch\")\n",
    "# else:\n",
    "#     # 多文件：用文件名（去后缀）\n",
    "#     batch_names = [os.path.splitext(os.path.basename(p))[0] for p in ARGS[\"inputs\"]]\n",
    "\n",
    "# batch_labels_str = np.array([batch_names[int(i)] for i in batches], dtype=str)\n",
    "# batch_labels_str = adata.obs[\"batch\"].astype(str).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e792096",
   "metadata": {},
   "source": [
    "## 训练 DisentAE（可跳过/继续）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd056924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Using device: cpu\n",
      "Epoch 1/50 | Recon 29.1623 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 2/50 | Recon 27.1003 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 3/50 | Recon 26.6052 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 4/50 | Recon 26.1605 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 5/50 | Recon 25.8523 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 6/50 | Recon 25.4821 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 7/50 | Recon 25.1949 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 8/50 | Recon 24.8978 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 9/50 | Recon 24.6191 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 10/50 | Recon 24.3467 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 11/50 | Recon 24.0790 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 12/50 | Recon 23.8284 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 13/50 | Recon 23.5908 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 14/50 | Recon 23.3410 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 15/50 | Recon 23.1279 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 16/50 | Recon 22.8789 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 17/50 | Recon 22.6681 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 18/50 | Recon 22.4649 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 19/50 | Recon 22.2604 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 20/50 | Recon 22.0702 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 21/50 | Recon 21.9136 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 22/50 | Recon 21.7183 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 23/50 | Recon 21.5576 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 24/50 | Recon 21.3983 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 25/50 | Recon 21.2564 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 26/50 | Recon 21.0973 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 27/50 | Recon 20.9850 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 28/50 | Recon 20.8808 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 29/50 | Recon 20.7372 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 30/50 | Recon 20.6244 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 31/50 | Recon 20.5145 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 32/50 | Recon 20.3999 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 33/50 | Recon 20.2974 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 34/50 | Recon 20.1907 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 35/50 | Recon 20.1316 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 36/50 | Recon 20.0650 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 37/50 | Recon 19.9498 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 38/50 | Recon 19.8948 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 39/50 | Recon 19.8266 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 40/50 | Recon 19.7679 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 41/50 | Recon 19.7038 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 42/50 | Recon 19.6282 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 43/50 | Recon 19.5601 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 44/50 | Recon 19.4987 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 45/50 | Recon 19.4502 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 46/50 | Recon 19.3927 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 47/50 | Recon 19.3414 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 48/50 | Recon 19.3042 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 49/50 | Recon 19.2536 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "Epoch 50/50 | Recon 19.1987 | Content(adv) 0.0000 | Batch(z_b) 0.0000\n",
      "[Info] Zc shape: (8573, 32), Zb shape: (8573, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8573, 32), (8573, 16))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pth_model = os.path.join(ARGS[\"outdir\"], \"model.pt\")\n",
    "pth_Zc = os.path.join(ARGS[\"outdir\"], \"Zc.npy\")\n",
    "pth_Zb = os.path.join(ARGS[\"outdir\"], \"Zb.npy\")\n",
    "\n",
    "can_skip_train = (\n",
    "    ARGS[\"resume\"]\n",
    "    and old_manifest is not None\n",
    "    and old_manifest.get(\"inputs\") == curr_manifest[\"inputs\"]\n",
    "    and old_manifest.get(\"params\") == curr_manifest[\"params\"]\n",
    "    and os.path.exists(pth_model) and os.path.exists(pth_Zc) and os.path.exists(pth_Zb)\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = ARGS[\"device\"]\n",
    "print(f\"[Info] Using device: {device}\")\n",
    "\n",
    "if can_skip_train and not ARGS[\"force\"]:\n",
    "    print(\"[Cache] 发现训练产物，直接加载\")\n",
    "    n_batch = int(batches.max()) + 1\n",
    "    model = DisentAE(X.shape[1], n_batch, ARGS[\"zc_dim\"], ARGS[\"zb_dim\"]).to(device)\n",
    "    model.load_state_dict(torch.load(pth_model, map_location=device))\n",
    "    model.eval()\n",
    "    Zc = np.load(pth_Zc)\n",
    "    Zb = np.load(pth_Zb)\n",
    "else:\n",
    "    model, Zc, Zb = train_disentae(\n",
    "        X, batches,\n",
    "        zc_dim=ARGS[\"zc_dim\"], zb_dim=ARGS[\"zb_dim\"],\n",
    "        batch_size=ARGS[\"batch_size\"], epochs=ARGS[\"epochs\"],\n",
    "        lr=ARGS[\"lr\"], device=device,\n",
    "        grl_lambda=ARGS[\"grl_lambda\"], inject_noise_std=ARGS[\"inject_noise_std\"]\n",
    "    )\n",
    "    print(f\"[Info] Zc shape: {Zc.shape}, Zb shape: {Zb.shape}\")\n",
    "    torch.save(model.state_dict(), pth_model)\n",
    "    np.save(pth_Zc, Zc)\n",
    "    np.save(pth_Zb, Zb)\n",
    "    save_manifest(ARGS[\"outdir\"], curr_manifest)\n",
    "\n",
    "Zc.shape, Zb.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671cc63",
   "metadata": {},
   "source": [
    "## MNN 迭代对齐（每次执行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc7075e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Zc_corr shape: (8573, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8573, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Zc_list = [Zc[batches == i] for i in range(int(batches.max()) + 1)]\n",
    "Zc_corr_list = apply_mnn_correction_iterative(Zc_list, k=ARGS[\"k_mnn\"])\n",
    "\n",
    "Zc_corr = np.vstack(Zc_corr_list)\n",
    "print(f\"[Info] Zc_corr shape: {Zc_corr.shape}\")\n",
    "np.save(os.path.join(ARGS[\"outdir\"], \"Zc_corrected.npy\"), Zc_corr)\n",
    "Zc_corr.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe7f143",
   "metadata": {},
   "source": [
    "## 解码到“去批次”的表达矩阵（每次执行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f5ff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Xcorr shape: (8573, 1222)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8573, 1222)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Xcorr_batches = decode_corrected_expression(model, Zc_corr_list, device=device)\n",
    "Xcorr = np.vstack(Xcorr_batches)\n",
    "print(f\"[Info] Xcorr shape: {Xcorr.shape}\")\n",
    "np.save(os.path.join(ARGS[\"outdir\"], \"X_corrected.npy\"), Xcorr)\n",
    "\n",
    "# 也输出 TSV（大文件可能较慢/较大，请按需保留或注释掉）\n",
    "np.savetxt(os.path.join(ARGS[\"outdir\"], \"Zc_corrected.tsv\"), Zc_corr, delimiter=\"\\t\")\n",
    "np.savetxt(os.path.join(ARGS[\"outdir\"], \"X_corrected.tsv\"), Xcorr, delimiter=\"\\t\")\n",
    "Xcorr.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db3129c",
   "metadata": {},
   "source": [
    "## 可选 UMAP 可视化（Before/After）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12bbc3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adata.obs 中的所有列（元数据）:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "adata_X = AnnData(X)\n",
    "print(\"adata.obs 中的所有列（元数据）:\")\n",
    "print(adata_X.obs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6003612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warn] visualize_correction 调用失败，已跳过。错误信息：'batch'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # === 先从原数据里取出标签（顺序需与 X / Zc_corr 保持一致）===\n",
    "    # 如果你的 preprocess_batches 是按 adata_list 的顺序拼的行，\n",
    "    # 下面这样拼接就与 X/Zc_corr 对齐：\n",
    "    batch_labels = np.concatenate([ad.obs[\"batch\"].astype(str).values for ad in adata_list])\n",
    "    cell_types   = np.concatenate([ad.obs[\"cell_type\"].astype(str).values for ad in adata_list])\n",
    "\n",
    "    # ========== X 原始空间（Before）==========\n",
    "    adata_X = AnnData(X)\n",
    "    adata_X.obs[\"batch\"]     = batch_labels\n",
    "    adata_X.obs[\"cell_type\"] = cell_types\n",
    "\n",
    "    sc.pp.scale(adata_X, max_value=10)\n",
    "    sc.tl.pca(adata_X)\n",
    "    sc.pp.neighbors(adata_X)\n",
    "    sc.tl.umap(adata_X)\n",
    "    sc.pl.umap(adata_X, color=\"batch\", title=\"Before correction (by batch)\", save=\"_before_batch.png\")\n",
    "    sc.pl.umap(adata_X, color=\"cell_type\", title=\"Before correction (by cell type)\", save=\"_before_celltype.png\")\n",
    "\n",
    "    # ========== Zc_corr 空间（After）==========\n",
    "    adata_Zc = AnnData(Zc_corr)\n",
    "    adata_Zc.obs[\"batch\"]     = batch_labels\n",
    "    adata_Zc.obs[\"cell_type\"] = cell_types\n",
    "\n",
    "    outdir = \"embeddings\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    out_path = os.path.join(outdir, \"my.npy\")\n",
    "    X = np.asarray(Zc_corr)\n",
    "    np.save(out_path, X)\n",
    "    print(f\"[OK] Harmony -> {out_path} shape={X.shape}\")\n",
    "\n",
    "    sc.pp.scale(adata_Zc, max_value=10)\n",
    "    sc.tl.pca(adata_Zc)\n",
    "    sc.pp.neighbors(adata_Zc)\n",
    "    sc.tl.umap(adata_Zc)\n",
    "    sc.pl.umap(adata_Zc, color=\"batch\", title=\"After correction (by batch)\", save=\"_after_batch.png\")\n",
    "    sc.pl.umap(adata_Zc, color=\"cell_type\", title=\"After correction (by cell type)\", save=\"_after_celltype.png\")\n",
    "\n",
    "    print(\"[Info] 可视化保存至当前工作目录（或 scanpy 配置的 figure 目录）\")\n",
    "except Exception as e:\n",
    "    print(f\"[Warn] 可视化失败，已跳过。错误信息：{e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbdbf36",
   "metadata": {},
   "source": [
    "## 完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e46fe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done] All artifacts are saved in: outputs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"[Done] All artifacts are saved in:\", ARGS[\"outdir\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b68b98",
   "metadata": {},
   "source": [
    "\n",
    "## 评估与可视化（ARI / NMI / ASW_celltype / ASW_batch / iLISI / KL）\n",
    "\n",
    "如果你有**细胞类型标签**（与样本顺序一致），请在下方把 `CELL_TYPES` 设为：\n",
    "- 一个 `list/ndarray`（长度 N），或\n",
    "- 指向一个包含 N 行、每行一个标签的 `TSV/CSV/TXT` 文件路径（自动读取第一列）。\n",
    "\n",
    "若未提供细胞类型，代码将自动跳过 ARI/NMI 与 ASW_celltype，仅计算批次相关指标（ASW_batch、iLISI、KL）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa1ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 安装/导入评估工具（已生成在 /mnt/data/）\n",
    "import sys, os, numpy as np\n",
    "sys.path.append(\"/mnt/data\")\n",
    "from sc_integration_metrics import (\n",
    "    compute_ari_nmi, compute_asw_celltype, compute_asw_batch,\n",
    "    compute_ilisi, compute_local_kl, evaluate_all_with_plots,\n",
    "    scatter_2d, bar_metrics, histogram\n",
    ")\n",
    "\n",
    "# === 参数：提供细胞类型标签（可选） ===\n",
    "# CELL_TYPES = None  # 1) 直接给一个与样本顺序一致的list/ndarray；或 2) 给路径字符串（见下）\n",
    "\n",
    "\n",
    "# 如果给了路径，尝试读取第一列作为标签\n",
    "def _maybe_load_labels(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, (list, tuple, np.ndarray)):\n",
    "        return np.asarray(x)\n",
    "    if isinstance(x, str) and os.path.exists(x):\n",
    "        # 读第一列\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            s = pd.read_csv(x, sep=None, engine=\"python\", header=None).iloc[:,0].astype(str).values\n",
    "            return s\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            s = np.loadtxt(x, dtype=str)\n",
    "            return s\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "# cell_types = _maybe_load_labels(CELL_TYPES)\n",
    "# print(\"[Eval] cell_types provided:\", \"YES\" if cell_types is not None else \"NO\")\n",
    "\n",
    "# === 选择要评估的嵌入 ===\n",
    "# 你可以选择 Zc_before / Zc_after(Zc_corr) / UMAP坐标 等\n",
    "X_EMB = Zc_corr  # 默认使用校正后的 Zc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eda7ee7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cell_types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# === 计算并出图 ===\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcell_types\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 仅批次相关的指标\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# asw_b = compute_asw_batch(X_EMB, batches)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# ilisi, ilisi_norm, ilisi_dist = compute_ilisi(X_EMB, batches, k=90, return_distribution=True)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# mean_kl, dkl_dist = compute_local_kl(X_EMB, batches, k=50, return_distribution=True)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     asw_b \u001b[38;5;241m=\u001b[39m compute_asw_batch(X_EMB, batch_labels_str)\n\u001b[1;32m      9\u001b[0m     ilisi, ilisi_norm, ilisi_dist \u001b[38;5;241m=\u001b[39m compute_ilisi(X_EMB, batch_labels_str, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m, return_distribution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cell_types' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 计算并出图 ===\n",
    "if cell_types is None:\n",
    "    # 仅批次相关的指标\n",
    "    # asw_b = compute_asw_batch(X_EMB, batches)\n",
    "    # ilisi, ilisi_norm, ilisi_dist = compute_ilisi(X_EMB, batches, k=90, return_distribution=True)\n",
    "    # mean_kl, dkl_dist = compute_local_kl(X_EMB, batches, k=50, return_distribution=True)\n",
    "\n",
    "    asw_b = compute_asw_batch(X_EMB, batch_labels_str)\n",
    "    ilisi, ilisi_norm, ilisi_dist = compute_ilisi(X_EMB, batch_labels_str, k=90, return_distribution=True)\n",
    "    mean_kl, dkl_dist = compute_local_kl(X_EMB, batch_labels_str, k=50, return_distribution=True)\n",
    "\n",
    "    scatter_2d(X_EMB, batches, title=\"Embedding colored by Batch\", assume_2d=False)\n",
    "    bar_metrics(\n",
    "        {\n",
    "            \"ASW_batch\": asw_b,\n",
    "            \"iLISI_norm\": ilisi_norm,\n",
    "            \"KL_local\": mean_kl,\n",
    "        },\n",
    "        title=\"Batch-mixing Metrics Summary\",\n",
    "    )\n",
    "    if ilisi_dist is not None:\n",
    "        histogram(ilisi_dist, title=\"iLISI (per-cell effective #batches)\", xlabel=\"effective batches\")\n",
    "    if dkl_dist is not None:\n",
    "        histogram(dkl_dist, title=\"Local KL divergence (neighborhood vs global)\", xlabel=\"D_KL\")\n",
    "\n",
    "    metrics = {\n",
    "        \"ARI\": np.nan,\n",
    "        \"NMI\": np.nan,\n",
    "        \"ASW_celltype\": np.nan,\n",
    "        \"ASW_batch\": asw_b,\n",
    "        \"iLISI\": ilisi,\n",
    "        \"iLISI_norm\": ilisi_norm,\n",
    "        \"KL_local_mean\": mean_kl,\n",
    "    }\n",
    "else:\n",
    "    # 计算全部六项指标并可视化\n",
    "    results = evaluate_all_with_plots(\n",
    "        X_emb=X_EMB,\n",
    "        celltype_labels=cell_types,\n",
    "        batch_labels=batches,\n",
    "        assume_2d=False,\n",
    "        k_ilisi=90,\n",
    "        k_kl=50,\n",
    "        clustering=\"kmeans\",\n",
    "        n_clusters=None,  # 默认=细胞类型的数量\n",
    "    )\n",
    "    metrics = {k: results[k] for k in [\n",
    "        \"ARI\",\"NMI\",\"ASW_celltype\",\"ASW_batch\",\"iLISI\",\"iLISI_norm\",\"KL_local_mean\"\n",
    "    ]}\n",
    "\n",
    "print(\"\\n[Metrics]\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k:15s} : {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c550f34",
   "metadata": {},
   "source": [
    "\n",
    "> 备注：\n",
    "> - `ASW_batch` 已将 Silhouette 映射到 [0,1]（越大批次越混合）。\n",
    "> - `iLISI` 与 `iLISI_norm` 分别是“有效批次数”的均值与其按真实批次数归一化的版本。\n",
    "> - `KL_local_mean` 是每个点邻域批次分布相对全局分布的平均 KL 散度（越小越好）。\n",
    "> - ARI / NMI / ASW_celltype 需要真实细胞类型标签。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
