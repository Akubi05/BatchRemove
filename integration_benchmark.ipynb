{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5500d67f",
   "metadata": {},
   "source": [
    "\n",
    "# Single-cell Integration Benchmark\n",
    "**Methods:** DESC / fastMNN / Harmony / iMAP / LIGER / Scanorama / Seurat / Uncorrect  \n",
    "**Metrics:** ARI, NMI, ASW_celltype, ASW_batch, iLISI, KL divergence\n",
    "\n",
    "- **ARI / NMI**：sklearn（以 KMeans 聚类与真值 cell type 对齐）  \n",
    "- **ASW_celltype / ASW_batch**：silhouette；其中 ASW_batch 使用 `(1 - silhouette)/2 ∈ [0,1]`（越大越混合）  \n",
    "- **iLISI**：优先使用 R 包 `lisi::compute_lisi`（需 rpy2 + R）；否则回退为 Python 近似（邻域批次比例熵的指数）  \n",
    "- **KL**：本地邻域批次分布相对**全局**批次分布的 D_KL 均值（越小越好）\n",
    "\n",
    "> 你只需提供各方法的**嵌入矩阵**（与细胞顺序一致），Notebook 会统一评测与作图。未提供的会跳过。`Uncorrect` 若留空，会用 Scanpy 预处理得到 50 PCs 作为基线。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4ba17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] rpy2 或 R 包 lisi 不可用：iLISI 将使用 Python 近似。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, numpy as np, pandas as pd\n",
    "import scanpy as sc\n",
    "from anndata import AnnData\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# iLISI (R) \n",
    "R_AVAILABLE = False\n",
    "try:\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects import pandas2ri\n",
    "    from rpy2.robjects.packages import importr\n",
    "    pandas2ri.activate()\n",
    "    lisi_pkg = importr(\"lisi\")\n",
    "    R_AVAILABLE = True\n",
    "except Exception:\n",
    "    print(\"[Info] rpy2 或 R 包 lisi 不可用：iLISI 将使用 Python 近似。\")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 120\n",
    "sc.settings.verbosity = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2ca1c",
   "metadata": {},
   "source": [
    "## Parameters（请在此修改）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57247c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT DIR: benchmark_out\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 数据输入（两种方式选其一）===\n",
    "# 方式1：已合并的 .h5ad（需包含 obs['cell_type'], obs['batch']）\n",
    "# H5AD = \"bct_raw.h5ad\" \n",
    "H5AD = \"mural_raw.h5ad\" \n",
    "# H5AD = \"macaque_raw.h5ad\" \n",
    "MULTI_H5AD = None\n",
    "BATCH_KEY  = None\n",
    "# 方式2：多个 h5ad + 批次列名（若设置 BATCH_KEY，将忽略 H5AD）\n",
    "# MULTI_H5AD = [\"neurips2021_s1d3.h5ad\",\n",
    "#               \"neurips2021_s2d1.h5ad\",\n",
    "#               \"neurips2021_s3d7.h5ad\"]  # 例如 [\"s1d3.h5ad\", \"s2d1.h5ad\", \"s3d7.h5ad\"]\n",
    "# BATCH_KEY  = \"batch\"  # 例如 \"batch\"\n",
    "# \"inputs\": [\n",
    "#     \"mural_raw.h5ad\",\n",
    "# ],\n",
    "# \"batch_key\": \"batch\",           \n",
    "# \"cell_type\": \"cell_type1\",  \n",
    "\n",
    "# obs 列名\n",
    "# CELLTYPE_COL = \"celltype\"\n",
    "# BATCH_COL    = \"BATCH\"\n",
    "# CELLTYPE_COL = \"cell_type\"\n",
    "# BATCH_COL    = \"batch\"\n",
    "CELLTYPE_COL = \"cell_type1\"\n",
    "BATCH_COL    = \"batch\"\n",
    "# 各方法嵌入文件（行顺序必须与 adata 一致）。支持 .npy/.npz/.csv/.tsv/.txt\n",
    "EMBEDDING_FILES = {\n",
    "    \"Uncorrect\": \"embeddings/uncorrect.npy\",      # 若 None，将自动计算 50 PCs\n",
    "    \"DESC\":      None,\n",
    "    \"fastMNN\":   None,\n",
    "    \"Harmony\":   \"embeddings/harmony.npy\",\n",
    "    \"iMAP\":      None,\n",
    "    \"LIGER\":     None,\n",
    "    \"Scanorama\": \"embeddings/scanorama.npy\",\n",
    "    \"Seurat\":    \"embeddings/seurat.npy\",\n",
    "    \"MyModel\":   \"outputs/embeddings/MyModel.npy\"\n",
    "    # \"scDML\":     \"embeddings/scdml.npy\"\n",
    "}\n",
    "\n",
    "SCDML_CELLTYPE = \"embeddings/labels_celltype.npy\"\n",
    "SCDML_REASSIGN = \"embeddings/labels_reassign.npy\"\n",
    "\n",
    "# 预处理/评测参数\n",
    "N_TOP_GENES = 2000\n",
    "N_PCS_BASE  = 50    # Uncorrect 的 PCA 维度\n",
    "N_NEIGHBORS = 15\n",
    "K_ILISI     = 90\n",
    "K_KL        = 50\n",
    "UMAP_SEED   = 0\n",
    "OUTDIR      = \"benchmark_out\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "print(\"OUTPUT DIR:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e3d698",
   "metadata": {},
   "source": [
    "## 数据读取与 Uncorrect 基线（50 PCs）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f788ab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N cells: 30302 | N genes: 36162\n",
      "filtered out 11558 genes that are detected in less than 3 cells\n",
      "normalizing counts per cell\n",
      "    finished (0:00:00)\n",
      "extracting highly variable genes\n",
      "    finished (0:00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/envs/dachuang310/lib/python3.10/functools.py:889: UserWarning: zero-centering a sparse array/matrix densifies it.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA\n",
      "    with n_comps=50\n",
      "    finished (0:00:34)\n",
      "Uncorrect embedding: (30302, 50)\n",
      "[Info] 评测将基于过滤后细胞数: 30302\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _load_embedding_file(path: str):\n",
    "    path = str(path)\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext == \".npy\":\n",
    "        return np.load(path)\n",
    "    if ext == \".npz\":\n",
    "        data = np.load(path)\n",
    "        if \"X\" in data: return data[\"X\"]\n",
    "        for k in data.files: return data[k]\n",
    "        raise ValueError(\"npz 文件中未找到数组\")\n",
    "    if ext in [\".csv\", \".tsv\", \".txt\"]:\n",
    "        sep = \",\" if ext == \".csv\" else None\n",
    "        df = pd.read_csv(path, sep=sep, engine=\"python\", header=None)\n",
    "        return df.values\n",
    "    raise ValueError(f\"不支持的嵌入文件格式: {ext}\")\n",
    "\n",
    "# 载入 AnnData\n",
    "if MULTI_H5AD and BATCH_KEY:\n",
    "    adata_list = [sc.read_h5ad(p) for p in MULTI_H5AD]\n",
    "    for ad in adata_list:\n",
    "        if BATCH_KEY not in ad.obs:\n",
    "            raise ValueError(f\"'{BATCH_KEY}' 不在某个 h5ad 的 obs 中\")\n",
    "    # 用 scanpy 合并，并把批次写在 BATCH_COL\n",
    "    adata = sc.concat(adata_list, join=\"outer\", label=BATCH_COL,\n",
    "                      keys=[os.path.splitext(os.path.basename(p))[0] for p in MULTI_H5AD])\n",
    "else:\n",
    "    if not H5AD:\n",
    "        raise ValueError(\"请设置 H5AD，或使用 MULTI_H5AD + BATCH_KEY\")\n",
    "    adata = sc.read_h5ad(H5AD)\n",
    "\n",
    "# 提取标签\n",
    "cell_types = adata.obs[CELLTYPE_COL].astype(str).values if CELLTYPE_COL in adata.obs else None\n",
    "batch_labels = adata.obs[BATCH_COL].astype(str).values if BATCH_COL in adata.obs else None\n",
    "print(\"N cells:\", adata.n_obs, \"| N genes:\", adata.n_vars)\n",
    "\n",
    "# 计算 Uncorrect 基线：50 PCs\n",
    "adata_unc = adata.copy()\n",
    "sc.pp.filter_cells(adata_unc, min_genes=200)\n",
    "sc.pp.filter_genes(adata_unc, min_cells=3)\n",
    "sc.pp.normalize_total(adata_unc, target_sum=1e4)\n",
    "sc.pp.log1p(adata_unc)\n",
    "sc.pp.highly_variable_genes(adata_unc, n_top_genes=N_TOP_GENES, subset=True)\n",
    "sc.pp.scale(adata_unc, max_value=10)\n",
    "sc.tl.pca(adata_unc, n_comps=N_PCS_BASE, svd_solver=\"arpack\")\n",
    "X_uncorrect = adata_unc.obsm[\"X_pca\"]\n",
    "print(\"Uncorrect embedding:\", X_uncorrect.shape)\n",
    "\n",
    "# === 关键：将评测基准切换为“过滤后”的细胞，并与 adata_unc 顺序完全一致 ===\n",
    "# 保存原始细胞顺序（9288）\n",
    "obs_before = pd.Index(adata.obs_names)\n",
    "\n",
    "# 过滤后细胞名（顺序与 adata_unc 一致）\n",
    "cells_new = adata_unc.obs_names.to_numpy()\n",
    "\n",
    "# 计算过滤后细胞在原始顺序里的位置索引\n",
    "idx = obs_before.get_indexer(cells_new)   # shape=(8573,)\n",
    "if (idx < 0).any():\n",
    "    missing = cells_new[idx < 0]\n",
    "    raise ValueError(f\"在原始 adata 中找不到这些细胞：{missing[:5]} ... 共 {len(missing)} 个\")\n",
    "\n",
    "# 2) 用这个集合对子集化原始 adata，并按 adata_unc 的顺序重排\n",
    "adata = adata[cells_new].copy()   # 先按名称取交集\n",
    "adata = adata[adata_unc.obs_names].copy()  # 再确保顺序一致（保险起见）\n",
    "\n",
    "# 3) 重新提取标签，并把 n_cells 更新为过滤后的数量\n",
    "cell_types = adata.obs[CELLTYPE_COL].astype(str).values if CELLTYPE_COL in adata.obs else None\n",
    "batch_labels = adata.obs[BATCH_COL].astype(str).values if BATCH_COL in adata.obs else None\n",
    "n_cells = adata.n_obs\n",
    "print(\"[Info] 评测将基于过滤后细胞数:\", n_cells)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0797c2",
   "metadata": {},
   "source": [
    "## 指标函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42966706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def asw_celltype(X, y):\n",
    "    if y is None or len(np.unique(y)) < 2: return np.nan\n",
    "    return float(silhouette_score(X, y, metric=\"euclidean\"))\n",
    "\n",
    "def asw_batch(X, b):\n",
    "    if b is None or len(np.unique(b)) < 2: return np.nan\n",
    "    sil = silhouette_score(X, b, metric=\"euclidean\")\n",
    "    return float((1.0 - sil)/2.0)\n",
    "\n",
    "def ilisi_python(X, b, k=90):\n",
    "    if b is None: return np.nan, np.full(X.shape[0], np.nan)\n",
    "    b = np.asarray(b); n = X.shape[0]; B = len(np.unique(b))\n",
    "    k_eff = min(k, n)\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff).fit(X)\n",
    "    nbrs = nn.kneighbors(return_distance=False)\n",
    "    _, b_int = np.unique(b, return_inverse=True)\n",
    "    local_eff = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        neigh = nbrs[i]\n",
    "        counts = np.bincount(b_int[neigh], minlength=B).astype(float)\n",
    "        p = counts / counts.sum(); p = np.clip(p, 1e-12, 1.0)\n",
    "        H = -(p * np.log(p)).sum()\n",
    "        local_eff[i] = np.exp(H)\n",
    "    return float(local_eff.mean()), local_eff\n",
    "\n",
    "def ilisi_r(X, b, perplexity=30):\n",
    "    emb_df = pd.DataFrame(X, columns=[f\"dim{i+1}\" for i in range(X.shape[1])])\n",
    "    meta_df = pd.DataFrame({\"batch\": b})\n",
    "    emb_r  = ro.conversion.py2rpy(emb_df)\n",
    "    meta_r = ro.conversion.py2rpy(meta_df)\n",
    "    res = lisi_pkg.compute_lisi(emb_r, meta_r, ro.StrVector([\"batch\"]), perplexity=perplexity)\n",
    "    lis = np.array(res.rx2(\"batch\")).reshape(-1)\n",
    "    return float(lis.mean()), lis\n",
    "\n",
    "def local_kl(X, b, k=50):\n",
    "    if b is None: return np.nan, np.full(X.shape[0], np.nan)\n",
    "    b = np.asarray(b)\n",
    "    batches, b_int = np.unique(b, return_inverse=True)\n",
    "    B = len(batches)\n",
    "    Pg = np.bincount(b_int, minlength=B).astype(float); Pg /= Pg.sum()\n",
    "    Pg = np.clip(Pg, 1e-12, 1.0)\n",
    "    k_eff = min(k, X.shape[0])\n",
    "    nn = NearestNeighbors(n_neighbors=k_eff).fit(X)\n",
    "    nbrs = nn.kneighbors(return_distance=False)\n",
    "    dkl = np.zeros(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        neigh = nbrs[i]\n",
    "        Pl = np.bincount(b_int[neigh], minlength=B).astype(float); Pl /= Pl.sum()\n",
    "        Pl = np.clip(Pl, 1e-12, 1.0)\n",
    "        dkl[i] = np.sum(Pl * np.log(Pl / Pg))\n",
    "    return float(dkl.mean()), dkl\n",
    "\n",
    "def ari_nmi(X, y):\n",
    "    if y is None or len(np.unique(y)) < 2: return np.nan, np.nan\n",
    "    n_clusters = len(np.unique(y))\n",
    "    km = KMeans(n_clusters=n_clusters, n_init=10, random_state=0).fit(X)\n",
    "    pred = km.labels_\n",
    "    return float(adjusted_rand_score(y, pred)), float(normalized_mutual_info_score(y, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77d9f6",
   "metadata": {},
   "source": [
    "## 载入各方法嵌入并计算指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ef00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "def _maybe_transpose(X, n_cells, name=\"\"):\n",
    "    \"\"\"如果发现 X 的第二维等于细胞数，则自动转置\"\"\"\n",
    "    # 转成 numpy，兼容 DataFrame\n",
    "    Xv = X.values if hasattr(X, \"values\") else X\n",
    "    if hasattr(Xv, \"shape\") and Xv.ndim == 2:\n",
    "        r, c = Xv.shape\n",
    "        if r != n_cells and c == n_cells:\n",
    "            print(f\"[Fix] {name}: 检测到形状为({r},{c})，自动转置为({c},{r})\")\n",
    "            Xv = Xv.T\n",
    "    return Xv\n",
    "\n",
    "# [+] 新增：鲁棒读取 .npy / .pyr(pickle) / .csv / .tsv / .txt\n",
    "def _load_label_any(path, n_cells=None):\n",
    "    arr = None\n",
    "    try:\n",
    "        # 先试 npy\n",
    "        arr = np.load(path, allow_pickle=True)\n",
    "    except Exception:\n",
    "        # 再试 pickle（.pyr/.pkl）\n",
    "        try:\n",
    "            s = pd.read_pickle(path)\n",
    "            arr = s.values if hasattr(s, \"values\") else np.asarray(s)\n",
    "        except Exception:\n",
    "            # 最后试文本\n",
    "            try:\n",
    "                sep = \"\\t\" if path.endswith(\".tsv\") else \",\"\n",
    "                s = pd.read_csv(path, header=None, sep=sep)\n",
    "                arr = s.iloc[:, 0].to_numpy()\n",
    "            except Exception as e:\n",
    "                print(f\"[Warn] 无法读取标签文件 {path}: {e}\")\n",
    "                return None\n",
    "    arr = np.asarray(arr).reshape(-1)\n",
    "    arr = arr.astype(str)\n",
    "    if n_cells is not None and len(arr) != n_cells:\n",
    "        print(f\"[Warn] 标签 {os.path.basename(path)} 长度({len(arr)}) ≠ 细胞数({n_cells})，请确认顺序是否一致\")\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eece810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Skip] DESC: 未提供嵌入文件\n",
      "[Skip] fastMNN: 未提供嵌入文件\n",
      "[Skip] iMAP: 未提供嵌入文件\n",
      "[Skip] LIGER: 未提供嵌入文件\n"
     ]
    }
   ],
   "source": [
    "embeddings = OrderedDict()\n",
    "n_cells = adata.n_obs\n",
    "labels_len = len(batch_labels) if batch_labels is not None else n_cells\n",
    "if labels_len != n_cells:\n",
    "    print(f\"[Warn] 标签长度({labels_len}) ≠ 细胞数({n_cells})，请先对齐标签！\")\n",
    "\n",
    "# --- Uncorrect ---\n",
    "Xu = None\n",
    "if EMBEDDING_FILES.get(\"Uncorrect\"):\n",
    "    Xu = _load_embedding_file(EMBEDDING_FILES[\"Uncorrect\"])\n",
    "    Xu = _maybe_transpose(Xu, n_cells, name=\"Uncorrect\")\n",
    "else:\n",
    "    Xu = X_uncorrect\n",
    "    Xu = _maybe_transpose(Xu, n_cells, name=\"Uncorrect(fallback)\")\n",
    "\n",
    "if Xu is None or Xu.shape[0] != n_cells:\n",
    "    print(f\"[Warn] Uncorrect 行数({None if Xu is None else Xu.shape[0]}) ≠ 细胞数({n_cells})，已跳过该方法\")\n",
    "else:\n",
    "    embeddings[\"Uncorrect\"] = Xu\n",
    "\n",
    "# --- 其它方法 ---\n",
    "for name in [\"MyModel\",\"DESC\",\"fastMNN\",\"Harmony\",\"iMAP\",\"LIGER\",\"Scanorama\",\"Seurat\"]:\n",
    "    p = EMBEDDING_FILES.get(name)\n",
    "    if not p:\n",
    "        print(f\"[Skip] {name}: 未提供嵌入文件\")\n",
    "        continue\n",
    "    try:\n",
    "        Xm = _load_embedding_file(p)\n",
    "        Xm = _maybe_transpose(Xm, n_cells, name=name)\n",
    "\n",
    "        # ★ 关键对齐：若矩阵行数等于“原始 9288”，先按 idx 子集到 8573 并保持顺序一致\n",
    "        if Xm.shape[0] == len(obs_before):\n",
    "            Xm = Xm[idx]\n",
    "\n",
    "        if Xm.shape[0] != n_cells:\n",
    "            print(f\"[Warn] {name} 行数({Xm.shape[0]}) ≠ 细胞数({n_cells})，跳过\")\n",
    "        else:\n",
    "            embeddings[name] = Xm\n",
    "    except Exception as e:\n",
    "        print(f\"[Warn] 无法加载 {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e913bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Uncorrect: X shape = (30302, 50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> MyModel: X shape = (30302, 32)\n",
      "==> Harmony: X shape = (30302, 50)\n",
      "==> Scanorama: X shape = (30302, 50)\n",
      "==> Seurat: X shape = (30302, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARI</th>\n",
       "      <th>NMI</th>\n",
       "      <th>ASW_celltype</th>\n",
       "      <th>ASW_batch</th>\n",
       "      <th>iLISI</th>\n",
       "      <th>KL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Uncorrect</th>\n",
       "      <td>0.864393</td>\n",
       "      <td>0.870350</td>\n",
       "      <td>0.180905</td>\n",
       "      <td>0.495052</td>\n",
       "      <td>1.462206</td>\n",
       "      <td>1.059711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyModel</th>\n",
       "      <td>0.085910</td>\n",
       "      <td>0.100163</td>\n",
       "      <td>-0.043339</td>\n",
       "      <td>0.519164</td>\n",
       "      <td>3.337639</td>\n",
       "      <td>0.197512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harmony</th>\n",
       "      <td>0.939202</td>\n",
       "      <td>0.937747</td>\n",
       "      <td>0.213231</td>\n",
       "      <td>0.518558</td>\n",
       "      <td>3.291692</td>\n",
       "      <td>0.305639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scanorama</th>\n",
       "      <td>0.424838</td>\n",
       "      <td>0.572141</td>\n",
       "      <td>0.112822</td>\n",
       "      <td>0.474185</td>\n",
       "      <td>1.341958</td>\n",
       "      <td>1.114245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seurat</th>\n",
       "      <td>0.117358</td>\n",
       "      <td>0.128822</td>\n",
       "      <td>-0.026501</td>\n",
       "      <td>0.496428</td>\n",
       "      <td>1.972205</td>\n",
       "      <td>0.731611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ARI       NMI  ASW_celltype  ASW_batch     iLISI        KL\n",
       "method                                                                    \n",
       "Uncorrect  0.864393  0.870350      0.180905   0.495052  1.462206  1.059711\n",
       "MyModel    0.085910  0.100163     -0.043339   0.519164  3.337639  0.197512\n",
       "Harmony    0.939202  0.937747      0.213231   0.518558  3.291692  0.305639\n",
       "Scanorama  0.424838  0.572141      0.112822   0.474185  1.341958  1.114245\n",
       "Seurat     0.117358  0.128822     -0.026501   0.496428  1.972205  0.731611"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存: benchmark_out/metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 计算指标（再次保护）---\n",
    "results = []\n",
    "for method, X in embeddings.items():\n",
    "    if X.shape[0] != n_cells:\n",
    "        print(f\"[Skip] {method}: X 行数({X.shape[0]}) ≠ 细胞数({n_cells})\")\n",
    "        continue\n",
    "\n",
    "    print(f\"==> {method}: X shape = {X.shape}\")\n",
    "    row = {\"method\": method}\n",
    "\n",
    "    ARI, NMI = ari_nmi(X, cell_types) if cell_types is not None else (np.nan, np.nan)\n",
    "    row[\"ARI\"], row[\"NMI\"] = ARI, NMI\n",
    "\n",
    "    # ASW\n",
    "    row[\"ASW_celltype\"] = asw_celltype(X, cell_types) if cell_types is not None else np.nan\n",
    "    row[\"ASW_batch\"]    = asw_batch(X, batch_labels)\n",
    "\n",
    "    # iLISI\n",
    "    if R_AVAILABLE and batch_labels is not None:\n",
    "        try:\n",
    "            ilisi_mean, ilisi_dist = ilisi_r(X, batch_labels, perplexity=30)\n",
    "        except Exception as e:\n",
    "            print(f\"[Warn] iLISI(R) 失败，回退 Python 近似：{e}\")\n",
    "            ilisi_mean, ilisi_dist = ilisi_python(X, batch_labels, k=K_ILISI)\n",
    "    else:\n",
    "        ilisi_mean, ilisi_dist = ilisi_python(X, batch_labels, k=K_ILISI)\n",
    "    row[\"iLISI\"] = ilisi_mean\n",
    "    row[\"_ilisi_dist\"] = ilisi_dist\n",
    "\n",
    "    # KL\n",
    "    kl_mean, kl_dist = local_kl(X, batch_labels, k=K_KL)\n",
    "    row[\"KL\"] = kl_mean\n",
    "    row[\"_kl_dist\"] = kl_dist\n",
    "\n",
    "    results.append(row)\n",
    "\n",
    "df = pd.DataFrame(results).set_index(\"method\")\n",
    "display(df[[\"ARI\",\"NMI\",\"ASW_celltype\",\"ASW_batch\",\"iLISI\",\"KL\"]])\n",
    "df.drop(columns=[\"_ilisi_dist\",\"_kl_dist\"]).to_csv(os.path.join(OUTDIR, \"metrics_summary.csv\"))\n",
    "print(\"保存:\", os.path.join(OUTDIR, \"metrics_summary.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6540a2",
   "metadata": {},
   "source": [
    "## UMAP（按批次与细胞类型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ec7a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/envs/dachuang310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:20)\n",
      "computing UMAP\n",
      "    finished (0:00:13)\n",
      "WARNING: saving figure to file benchmark_out/umap_Uncorrect_batch.png\n",
      "保存: benchmark_out/umap_Uncorrect_batch.png\n",
      "computing neighbors\n",
      "    finished (0:00:02)\n",
      "computing UMAP\n",
      "    finished (0:00:13)\n",
      "WARNING: saving figure to file benchmark_out/umap_Uncorrect_celltype.png\n",
      "保存: benchmark_out/umap_Uncorrect_celltype.png\n",
      "computing neighbors\n",
      "    finished (0:00:02)\n",
      "computing UMAP\n",
      "    finished (0:00:12)\n",
      "WARNING: saving figure to file benchmark_out/umap_MyModel_batch.png\n",
      "保存: benchmark_out/umap_MyModel_batch.png\n",
      "computing neighbors\n",
      "    finished (0:00:02)\n",
      "computing UMAP\n",
      "    finished (0:00:12)\n",
      "WARNING: saving figure to file benchmark_out/umap_MyModel_celltype.png\n",
      "保存: benchmark_out/umap_MyModel_celltype.png\n",
      "computing neighbors\n",
      "    finished (0:00:02)\n",
      "computing UMAP\n",
      "    finished (0:00:12)\n",
      "WARNING: saving figure to file benchmark_out/umap_Harmony_batch.png\n",
      "保存: benchmark_out/umap_Harmony_batch.png\n",
      "computing neighbors\n",
      "    finished (0:00:02)\n",
      "computing UMAP\n",
      "    finished (0:00:12)\n",
      "WARNING: saving figure to file benchmark_out/umap_Harmony_celltype.png\n",
      "保存: benchmark_out/umap_Harmony_celltype.png\n",
      "computing neighbors\n",
      "    finished (0:00:02)\n",
      "computing UMAP\n",
      "    finished (0:00:12)\n",
      "WARNING: saving figure to file benchmark_out/umap_Scanorama_batch.png\n",
      "保存: benchmark_out/umap_Scanorama_batch.png\n",
      "computing neighbors\n",
      "    finished (0:00:02)\n",
      "computing UMAP\n",
      "    finished (0:00:12)\n",
      "WARNING: saving figure to file benchmark_out/umap_Scanorama_celltype.png\n",
      "保存: benchmark_out/umap_Scanorama_celltype.png\n",
      "computing neighbors\n",
      "    finished (0:00:04)\n",
      "computing UMAP\n",
      "    finished (0:02:15)\n",
      "WARNING: saving figure to file benchmark_out/umap_Seurat_batch.png\n",
      "保存: benchmark_out/umap_Seurat_batch.png\n",
      "computing neighbors\n",
      "    finished (0:00:03)\n",
      "computing UMAP\n",
      "    finished (0:02:02)\n",
      "WARNING: saving figure to file benchmark_out/umap_Seurat_celltype.png\n",
      "保存: benchmark_out/umap_Seurat_celltype.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scatter_umap(X, labels, title, out_png):\n",
    "    X = np.asarray(X)\n",
    "    assert X.ndim == 2\n",
    "    if labels is not None:\n",
    "        labels = np.asarray(labels)\n",
    "        assert len(labels) == X.shape[0], f\"labels({len(labels)}) != n_cells({X.shape[0]})\"\n",
    "\n",
    "    ad = AnnData(X)  # ad.X 不再用于 PCA\n",
    "    ad.obs[\"label\"] = (labels.astype(str) if labels is not None\n",
    "                       else pd.Series([\"NA\"]*X.shape[0], dtype=str).values)\n",
    "\n",
    "    # 直接复用已有嵌入作为“PCA”的表示\n",
    "    ad.obsm[\"X_pca\"] = X\n",
    "\n",
    "    # 用 X_pca 构图，不再调用 sc.tl.pca\n",
    "    sc.pp.neighbors(ad, n_neighbors=N_NEIGHBORS, use_rep=\"X_pca\")\n",
    "    sc.tl.umap(ad, random_state=UMAP_SEED)\n",
    "\n",
    "    old = sc.settings.figdir\n",
    "    sc.settings.figdir = OUTDIR\n",
    "    try:\n",
    "        sc.pl.umap(ad, color=\"label\", title=title, show=False, save=f\"_{out_png}\")\n",
    "        auto = os.path.join(OUTDIR, f\"umap_{out_png}\")\n",
    "        if os.path.exists(auto): print(\"保存:\", auto)\n",
    "    finally:\n",
    "        sc.settings.figdir = old\n",
    "\n",
    "\n",
    "for method, X in embeddings.items():\n",
    "    scatter_umap(X, batch_labels, f\"{method} — batch\",    f\"{method}_batch.png\")\n",
    "    if cell_types is not None:\n",
    "        scatter_umap(X, cell_types, f\"{method} — celltype\", f\"{method}_celltype.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
